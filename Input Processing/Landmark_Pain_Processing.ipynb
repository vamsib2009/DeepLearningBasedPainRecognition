{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8604,
     "status": "ok",
     "timestamp": 1732788415625,
     "user": {
      "displayName": "Bolisetti Sree Vamsi Krishna",
      "userId": "01973412395870973535"
     },
     "user_tz": -330
    },
    "id": "R4Fcxtah8sCM",
    "outputId": "994ae8cc-d01b-46ce-f639-2ed8fc801934"
   },
   "outputs": [],
   "source": [
    "%pip install mediapipe dlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to generate OFI images for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing output of a sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 34885,
     "status": "ok",
     "timestamp": 1732788483942,
     "user": {
      "displayName": "Bolisetti Sree Vamsi Krishna",
      "userId": "01973412395870973535"
     },
     "user_tz": -330
    },
    "id": "ZndILkOb8y51",
    "outputId": "0e5772c9-4d84-4e34-ce6e-2f964e8daaf2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "# Load video\n",
    "video_path = ''\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize dlib face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = \"C:\\\\Users\\\\VB\\\\Downloads\\\\shape_predictor_68_face_landmarks.dat\"  # <-- Update path if needed\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Output directory to save FLI images\n",
    "output_dir = \"FLI_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "max_frames = 128\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame_count >= max_frames:\n",
    "        break\n",
    "\n",
    "    # Process every 4th frame\n",
    "    if frame_count % 4 != 0:\n",
    "        frame_count += 1\n",
    "        continue\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "        for i in range(68):\n",
    "            x = landmarks.part(i).x\n",
    "            y = landmarks.part(i).y\n",
    "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "    # Save or display frame\n",
    "    output_path = os.path.join(output_dir, f\"fli_frame_{frame_count}.jpg\")\n",
    "    cv2.imwrite(output_path, frame)\n",
    "\n",
    "    # Optional: Display\n",
    "    cv2.imshow(\"Facial Landmarks\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the video path for no-pain (BL1) and pain (PA4) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1732459374482,
     "user": {
      "displayName": "Bolisetti Sree Vamsi Krishna",
      "userId": "01973412395870973535"
     },
     "user_tz": -330
    },
    "id": "RAG2Jb3NI1nt",
    "outputId": "a0bd4859-8223-431a-bc2d-5dbedce47e02"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to walk through the directory and find mp4 files containing \"BL1\"\n",
    "def find_bl1_mp4_files(directory):\n",
    "    bl1_files = []\n",
    "\n",
    "    # Walk through all files and subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file is an mp4 and contains \"BL1\" in the name\n",
    "            if file.endswith(\".mp4\") and \"PA4\" in file:\n",
    "                # Get the full path of the file\n",
    "                full_file_path = os.path.join(root, file)\n",
    "                bl1_files.append(full_file_path)\n",
    "\n",
    "    return bl1_files\n",
    "\n",
    "# Example usage: Provide your directory path\n",
    "directory_path = ''  #Replace with your directory path\n",
    "\n",
    "# Get list of mp4 files containing \"PA4\"\n",
    "bl1_mp4_files = find_bl1_mp4_files(directory_path)\n",
    "\n",
    "# Display the list\n",
    "for file in bl1_mp4_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to process video and same image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1819894,
     "status": "ok",
     "timestamp": 1732461231234,
     "user": {
      "displayName": "Bolisetti Sree Vamsi Krishna",
      "userId": "01973412395870973535"
     },
     "user_tz": -330
    },
    "id": "_INMRUomO8I4",
    "outputId": "31a6781d-ac04-4cf0-e0b3-cc3dec3be70f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "\n",
    "# List of video file paths\n",
    "video_paths = bl1_mp4_files  # Ensure this variable is defined\n",
    "\n",
    "# Output directory\n",
    "output_dir = ''\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5)\n",
    "\n",
    "# Landmark indices to keep (excluding chin/jawline)\n",
    "valid_indices = list(range(17, 68))  # Eyebrows, eyes, nose, and mouth\n",
    "\n",
    "# Exaggeration factor\n",
    "exaggeration_factor = 4\n",
    "\n",
    "# Process each video\n",
    "for video_path in video_paths:\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    print(f\"Processing video: {video_name}\")\n",
    "\n",
    "    video_output_dir = os.path.join(output_dir, video_name)\n",
    "    os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_count = 0\n",
    "    original_landmarks = None\n",
    "    previous_landmarks = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % 4 != 0 or frame_count > 132:\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        frame_count2 = frame_count - 4\n",
    "        image_filename = f\"{video_name}_Landmark_{frame_count2}.png\"\n",
    "        image_filepath = os.path.join(video_output_dir, image_filename)\n",
    "\n",
    "        # Skip processing if image already exists\n",
    "        if os.path.exists(image_filepath):\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for landmarks in results.multi_face_landmarks:\n",
    "                # Extract and filter landmark coordinates\n",
    "                landmark_coords = np.array([\n",
    "                    (int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0]))\n",
    "                    for landmark in landmarks.landmark\n",
    "                ])\n",
    "                valid_landmarks = landmark_coords[valid_indices]\n",
    "\n",
    "                # Store first frame landmarks for long-term movement\n",
    "                if original_landmarks is None:\n",
    "                    original_landmarks = valid_landmarks.copy()\n",
    "\n",
    "                # Calculate long-term movement\n",
    "                long_term_move = (valid_landmarks - original_landmarks) * exaggeration_factor\n",
    "\n",
    "                # Calculate short-term movement if not first frame\n",
    "                if previous_landmarks is not None:\n",
    "                    short_term_move = (valid_landmarks - previous_landmarks) * exaggeration_factor\n",
    "\n",
    "                    # Save quiver plot\n",
    "                    plt.figure(figsize=(2.56, 2.56), dpi=100)  # 256x256 resolution\n",
    "\n",
    "                    # Plot long-term vectors (from original landmarks) in red\n",
    "                    plt.quiver(original_landmarks[:, 0], original_landmarks[:, 1],\n",
    "                               long_term_move[:, 0], long_term_move[:, 1],\n",
    "                               angles='xy', scale_units='xy', scale=1, color='red',\n",
    "                               width=0.005, headwidth=3, headlength=5, headaxislength=4)\n",
    "\n",
    "                    # Plot short-term vectors (from previous landmarks) in blue\n",
    "                    plt.quiver(previous_landmarks[:, 0], previous_landmarks[:, 1],\n",
    "                               short_term_move[:, 0], short_term_move[:, 1],\n",
    "                               angles='xy', scale_units='xy', scale=1, color='blue',\n",
    "                               width=0.005, headwidth=3, headlength=5, headaxislength=4)\n",
    "\n",
    "                    plt.gca().invert_yaxis()\n",
    "                    plt.axis('off')\n",
    "                    plt.grid(False)\n",
    "                    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "                    plt.savefig(image_filepath, dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "                    plt.close()\n",
    "\n",
    "                previous_landmarks = valid_landmarks\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "print(\"MediaPipe landmark movement images with long-term (red) and short-term (blue) vectors saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPrKz5fMEv8WvK8xsmPD2Nj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
